---
title: "Test de Little para datos MCAR"
author: "J. Antonio García Ramirez"
date: "22 de octubre de 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Después de consultar el artículo de Roderick J. A. Little\cite{little} donde se propone una prueba para probar la hipótesis nula de que los datos faltantes en una muestra son MCAR (missing completely at random) se reporta un resumen del funcionamiento de la prueba, un ligero debate sobre los supuestos y conclusiones del mismo artículo y una reseña a su actual implementación en el lenguaje R.

Para resaltar lo sencillo de la prueba propuesta por Little en su artículo para la hipótesis nula de que los datos faltantes de una muestra con MCAR consideramos importante recordar la definición de datos que faltan aleatoriamente así como la notación empleada en el mismo artículo. 

## Definiciones

Denotamos como $y$ a una matriz de datos de tamaño $n \times p$ , 
de $n$ observaciones con $p$ variables y con $r$ una matriz con indicadores de cuándo un dato es faltante indicando con la unidad si el dato falta y cero en el otro caso. 
Un modelo completo para los datos y los datos faltantes especifica un mecanismo con distribución $f(y|\theta)$ para $y$ indexado por un conjunto de parámetros desconocido $\theta$ y con distribución $f(r|y, \phi)$ para $r$ dado $y$ e indexado por un conjunto de parámetros desconocido $\phi$.

Entonces podemos escribir a los datos $y$ como un conjunto dependiente de los valores observados y de los faltantes $y=(y_{obs}, y_{mis})$ donde $y_{obs}$ representa los datos observados de $y$ y $y_{mis}$ representa a los datos faltantes. Al igual que como vimos en clase, el artículo define los datos que faltan aleatoriamente (MCAR) si $f(r|y_{obs},y_{mis},\phi)=f(r|\phi)$ para toda $y_{obs}$ y $y_{mis}$, esto quiere decir que los valores faltantes no dependen de los valores observados así como de los valores faltantes.

Como paréntesis es interesante señalar que en su introducción del artículo Little hace referencia a otras pruebas para la hipótesis de que los datos son MAR (missing and random) y para probar que los datos son MCAR pero solo considerando pruebas univariadas, lo que conlleva a varios (por no decir a un número exhaustivo) de pruebas por pares de variables para probar la hipótesis nula (tales pruebas tienen asociado un estadístico que se distribuye como una distribución $t$). Sin embargo en vista de lo poco práctico de la prueba de Little, ya que la condición MCAR es más laxa que la MAR, no se consultaron tales pruebas.

## Notación 

Denotamos como $y_i$ al vector $(1 \times p)$ de valores para el caso $i$ en la ausencia de valores. Y denotamos también por $r_i=(1\times p)$ al vector de indicadores de datos faltantes para el caso $i$. $J$ es el número de patrones distintos de datos faltantes $r_i$ en la muestra.

Aquí es importante señalar la distinción entre el concepto de caso de la prueba y el de una observación por ejemplo si tenemos una muestra de tamaño 20 de 3 variables, es decir $y$ es de tamaño $20 \times 3$, y digamos que solo faltan dos valores en toda la muestra y que estos dos valores se presentan en la primer variable entonces estamos en presencia de un solo caso de ausencia de valores que en nuestra matriz $y_{mis}$ se presentan como $(1,0,0)$ en dos renglones pero solo representan un caso de valores que faltan.

Considerando lo anterior, para datos totalmente observados estos se consideran como el conteo de un solo patrón, el conjunto $S_j$ con $j=1,...,J$ representa el conjunto de patrones de datos que faltan con $m_j$ el número de casos en $S_j$ de esta manera $\sum_{j}m_j=n$, y denotamos como $p_j$ al número de variables observadas para los casos $S_j$. La matriz $D_j=(p \times p_j)$ indica que variables fueron observadas para el patrón $j$, la matriz tiene un una columna de unos para cada variable presente. 


Y la notación anterior permite identificar los siguientes vectores que son muy importantes en la formulación de la prueba:
Denotamos como $y_{obs,i}=(1\times p_j)$ al vector de valores observados de las variables para el caso $i$ es decir que solo es un conteo de las indicadoras. $\bar{y}_{obs,j}=m_j^{-1}\sum_{i \in S_j}y_{obs,i}$ es decir que es el vector de medias de las variables observadas en el patrón $j$. $\mu$ y $\Sigma$ son el vector $(1 \times p)$ y la matriz $(p \times p)$ para la media y covarianza poblacional de los datos $y_i$, $\hat{\mu}$ y $\hat{\Sigma}$ son los estimadores de máxima verosimilitud de la media y covarianza poblacional asumiendo que las $y_i$ son iid normales con mecanismo de datos ausentes ignorable, esta última observación es medular en la formulación de la prueba, y denotamos por $\Sigma^*=n\hat{\Sigma}/(n-1)$ como el estimador máximo verosímil de la matriz de covarianzas corregido por los grados de libertad.

Finalmente el artículo es explícito en la forma de construir los vectores $\mu_{obs,j}=\mu D_j$ de tamaños $(1 \times p_j)$ los vectores de medias observadas del patrón $j$. La matriz $\Sigma_{obs,j}=D_{j}^t\Sigma D_j$ de tamaña $(p_j \times p_j)$ la matriz de covarianzas de las variables en el patrón $j$.

Insistimos en recalcar lo importante de la notación del artículo pues en una primera inspección se puede pasar por alto el gran número de vectores de medias y covarianzas considerados en la prueba, que de hecho corresponden uno a uno con cada posible caso de valores ausentes.

## Las pruebas 


Posterior a la notación el artículo continúa definiendo la siguiente prueba, primero para el caso en que la matriz $\Sigma$ se conoce y $\mu^*$ es el estimador máximo verosímil de $\mu$ asumiendo que la muestra es MAR y que se conoce $\Sigma$, y siendo $\mu^*_{obs,j}=\mu^*D_j$.


Se propone el siguiente estadístico para la hipótesis nula de datos de tipo MCAR:


$$d_0^2=\sum_{j=1}^Jm_j(\bar{y}_{obs,j}-\mu^*_{obs,j})\Sigma^{-1}_{obs,j}(\bar{y}_{obs,j}-\mu^*_{obs,j})^{t}$$

Así la idea de que los datos $y_i$ tienen una distribución normal multivariada con media $\mu$ y covarianza $\Sigma$ con patrón de datos faltantes del tipo MCAR condicionados on $r_i$ tienen distribución:


$$(y_{obs,i}|r_{i})\sim N(\mu_{obs,j},\Sigma_{obs,j}), i\in S_j,1\leq j\leq J$$

Y si la muestra no es MCAR entonces las medias observadas varían a través de los patrones encontrados, sugiriendo el modelo alternativo de la prueba:


$$(y_{obs,i}|r_i)\sim N(v_{obs,j},\Sigma_{obs,j}), i\in S_j,1 \leq j\leq J$$

Donde los vectores $v$ representan los $(1 \times p_j)$ vectores de medias observados a diferencia de los $\mu_{obs,j}$ que se construyen con la información del $\mu$ máximo verosímil y las matrices $D_j$ 


En el artículo se prueba que $d_0^2$ es el estadístico de razón de verosimilitudes, que como recordamos de nuestro curso de inferencia estadística estos test de razón de verosimilitudes son uniformemente más potentes para la familia exponencial (cuando menos en el caso univariado), también el estadístico $d_0^2$ tiene distribución $\chi^2$ con $f=\sum p_j -p$ grados de libertad (aquí vale la pena notar lo parecido de los grados de libertad con los que se obtienen en las tablas de contingencia) y finalmente que si los datos son MCAR (es decir que satisfacen la hipótesis nula ) $d_0^2$ se distribuye asintóticamente como $\chi^2$ con los mismos grados de libertad $f$, es decir que para tamaños de muestra grandes la hipótesis en la distribución normal puede ser relajada.


En los casos más aplicables en que no se conoce la matriz de covarianzas $\Sigma$ se reemplaza $\mu^*$ y $\Sigma$ en la definición de $d_0^2$ por sus estimadores máximo verosímiles normales multivariados $\hat{\mu}$ y $\Sigma^*$, para definir el estadístico $d^2$.



Bajo el supuesto de que los datos observados tienen información de todos los pares de variables de manera que todas las medias y covarianzas son estimables , y que los datos son MCAR, entonces la distribución de $y_i$ debe tener momentos de orden cuatro finitos (aunque el artículo no es explícito en este detalle es consecuencia de que las varianzas para cada variable existan y que se presente información de todos los pares de variables), lo que finalmente se traduce en que el estadístico $d^2$ tiene distribución asintótica $\chi^2$ con $f$ grados de libertad. 


Si bien el resultado anterior luce gentil, no debe escapar a nuestra atención que su simple evaluación requiere del cómputo de los estimadores máximo verosímiles de la media y la covarianza corregida, lo cual aunque el artículo menciona que se puede lograr conseguir fácilmente en la práctica puede no resultar tan sencillo. 


## Discusión de la distribución en muestra pequeñas

Cuando no se tiene el resultado asintótico, es decir que el tamaño de muestra es pequeño el articulo continua con una discusión acerca de lo complejo que llega a ser el patrón general de datos faltantes. Enunciando, y ejemplificando con un ejemplo, lo siguiente: 


Si se tiene un arreglo de los patrones monótono, donde la variable $Y_q$ es observada más veces que $Y_{q-1}$ con $q=1,...,p-1$ entonces si $n_q$ es el número de casos para el cual $Y_q$ es observada,$n=n_1\geq n_2\geq ...\geq n_p$ se tiene que en muestras pequeñas:

$$d^2= \sum_{q=1}^{p-1}(n_q-1)(k_q-1)F_{q.12...q-1}/(n_q-k_q + (k_q-1)F_{q.12...q-1})$$ 

Donde $n_q$ es el número de casos con la variable $Y_q$ observada, $k_q$ es el número de patrones con la variable $Y_q$ observada y $F_{q.l}$ el estadístico $F$ de la covarianza de $Y_q$ en los restantes $l$ patrones con $Y_q$ observada ajustado por $Y_l$. Si bien lo anterior ejemplifica lo costoso que puede llegar a ser el cálculo del estadístico, además bajo la hipótesis de normalidad y MCAR cada contribución de los términos de la suma anterior son independientes por lo que de nuevo el estadístico $d^2$ es una suma de estadísticos $F$ independientes manteniendo la distribución $\chi^2$.


En las secciones siguientes del artículo se habla acerca de un pequeño estudio de simulación con diferentes tamaños de muestra (para ser precisos los tamaños son 20,40 y 80) con únicamente cuatro variables y con tres tipos de datos, normales, lognormales y $t$ con tres grados de libertad (los casos de colas pesadas) donde después de argumentar sobre variaciones en la definición del estadístico $d^2$ que tienen las mismas propiedades asintóticas, el mismo Little sugiere que la prueba es sensible al supuesto de normalidad y que incluso cumpliendo ese supuesto la distribución asintótica bajo la hipótesis nula (que aparte de normalidad recordemos que presupone origen MCAR en los datos) luce poco confiable para tamaños de muestra pequeños.


En conclusión la prueba es poco confiable en tamaños de muestra pequeños y en caso de no cumplir la hipótesis nula, por lo cual parece ser poco aplicable pero recordemos que lo importante de las pruebas de hipótesis es cómo se construyen sus hipótesis nulas, entonces cuando menos disponemos de una prueba para rechazar la hipótesis de MCAR.


Concluimos reseñando, en las siguientes líneas de código, una implementación de la prueba de Little en el lenguaje R (en el package *BaylorEdPsych* disponible y actualizado) y resaltando los tres posibles casos del conjunto de 20 observaciones del conjunto de datos del que se incluye como ejemplo.  

El conjunto de datos muestra es el siguiente:

Donde notamos cuatro posibles casos, la ausencia unicamente de la variable $WB$, la usencia unicamente de la variable $JP$ la usencia de las dos variables anteriores y la no ausencia de ninguna variable.

```{r}
library(BaylorEdPsych)
data(EndersTable1_1)
EndersTable1_1
```

Como es de esperar el conjunto anterior no es MCAR puesto que la primer variable simpre se observa por lo que la implementación del test arroja lo siguiente, donde se aprecian los cuatro casos de valores que faltan con su respectivo número $p_j$, los grados de libertad del estadístico y el $p-valor$ de la prueba con lo que se rechaza la hipotesis de datos MCAR.


```{r}
LittleMCAR(EndersTable1_1)
```






 

 
\begin{thebibliography}{1}
\bibitem{little}
Little, R. J. A. (1988). \textit{A test of missing completely at random for multivariate data with missing values}. Journal of the American Statistical Association , 83(404), 1198-1202


\end{thebibliography}