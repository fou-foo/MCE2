} else {return(Inf)} #si un coeficiente al menos es no significativo
#regresamos un BIC infinito
}, 2:lag)
}
if (option == 'c')
{
datos[, 'c'] <- rep(1, dim(datos)[1] )
#aplicamos el test para cada lag
resultado <- mapply(function(x)
{
formula <- paste(names(datos)[x], collapse = '+')
formula <- as.formula(paste0('y1 ~ ', formula))
modelo <- lm(formula , data = datos )
resumen <- summary(modelo)
# nos fijamos si todos los coeficientes de la regresion
# son significativos individualmente
coeficientes.significativos <- resumen$coefficients[, 'Pr(>|t|)']
coeficientes.significativos <- coeficientes.significativos <= 0.05
if(sum(coeficientes.significativos) == 2)
{
big <- BIC(modelo)
# en caso de que todos los coeficientes sean significativos regresamos
#el BIC de la regresion
return(big)
}else {return(Inf)} #si un coeficiente al menos es no significativo
#regresamos un BIC infinito
}, 2:lag)
}
if (option == 't')
{
datos[, 't'] <- cumsum(1:dim(datos)[1])
#aplicamos el test para cada lag
resultado <- mapply(function(x)
{
formula <- paste(c(names(datos)[x], 't'), collapse = '+')
formula <- as.formula(paste0('y1 ~ ', formula, '-1'))
modelo <- lm(formula , data = datos )
resumen <- summary(modelo)
# nos fijamos si todos los coeficientes de la regresion
# son significativos individualmente
coeficientes.significativos <- resumen$coefficients[, 'Pr(>|t|)']
coeficientes.significativos <- coeficientes.significativos <= 0.05
if(sum(coeficientes.significativos) == 2)
{
big <- BIC(modelo)
# en caso de que todos los coeficientes sean significativos regresamos
#el BIC de la regresion
return(big)
}else { return(Inf)}  #si un coeficiente al menos es no significativo
#regresamos un BIC infinito
}, 2:lag)
}
if (option == 'both')
{
datos[, 't'] <- cumsum(1:dim(datos)[1])
#aplicamos el test para cada lag
resultado <- mapply(function(x)
{
formula <- paste(c(names(datos)[2:(x)], 't'), collapse = '+')
formula <- as.formula(paste0('y1 ~ ', formula))
modelo <- lm(formula , data = datos )
resumen <- summary(modelo)
# nos fijamos si todos los coeficientes de la regresion
# son significativos individualmente
coeficientes.significativos <- resumen$coefficients[, 'Pr(>|t|)']
coeficientes.significativos <- coeficientes.significativos <= 0.05
if(sum(coeficientes.significativos) == 3)
{
big <- BIC(modelo)
# en caso de que todos los coeficientes sean significativos regresamos
#el BIC de la regresion
return(big)
} else { return(Inf)}  #si un coeficiente al menos es no significativo
#regresamos un BIC infinito
}, 2:lag)
}
parsimonia <- which.min(resultado)
names(parsimonia) <- 'Lag optimo'
return(parsimonia)
}
diferencia <- today()- ymd('2008-01-01')
fecha <- as.numeric(diferencia)
today()-days(fecha) #checar fecha de inicio
first.date <- Sys.Date() - fecha #actualización en tiempo real
last.date <- Sys.Date()
freq.data <- 'weekly'  # frecuencia semanal
# lectura de tickerts
Componentes_Investing_com_United_States_500 <- read_csv("Componentes Investing.com United States 500.csv") # previanmente descargamos de
#https://mx.investing.com/indices/investing.com-us-500-components los nombres de las empresas
tickers <- Componentes_Investing_com_United_States_500$Símbolo
companias <- BatchGetSymbols(tickers = tickers,
first.date = first.date,
last.date = last.date,
freq.data = freq.data,
do.complete.data = FALSE, #sihay nulos los descartamos
cache.folder = file.path(tempdir(),'BGS_Cache')) # cache in tempdir()
# comprobamos que variable es la que se registra 'price.close '
#a <- companias$df.tickers
#a <- subset(a, ticker=='A')
#sapply(a,class )
#a <- a[ a$price.open !=a$price.high,  ]
#a <- a[ a$price.low !=a$price.high,  ]
#a <- a[ a$price.low !=a$price.close ,  ]
#a <- a[ a$price.adjusted !=a$price.close ,  ]
#a <- unique(as.data.frame(a)) #identificamos la variable de interes
serie <- companias$df.tickers
class(serie) <- 'data.frame'
serie %>% select(ticker, ref.date, price.close ) -> serie# era open o close ?
SP500 <- BatchGetSymbols(tickers = "^GSPC",
first.date = first.date,
last.date = last.date,
freq.data = freq.data,
do.complete.data = FALSE, #sihay nulos los descartamos
cache.folder = file.path(tempdir(),'BGS_Cache'))
#names(SP500)
SP500 <- as.data.frame(SP500$df.tickers)[, c(2,4)]
sp.500 <- na.omit(SP500)
serie2 <- dcast(serie, ref.date ~ ticker, value.var = 'price.close' )
#write_csv(serie2, path='serie2.csv')
#serie2 <- read_csv( file='serie2.csv')
serie3 <- apply(serie2, 2, function(x) sum(is.na(x))) # identificamos series problematicas
#table(serie3)
malas <- which(serie3 > 8 )
serie4 <- serie2[,  !(colnames(serie2) %in% names(malas)) ]
serie5 <- na.omit(serie4)
class(serie5) <- 'data.frame'
serie5$ref.date <- as.Date(serie5$ref.date)
serie.cruda <- serie5 # para comparacion sin estacionalizar
par(mfrow=c(3,3))
#inspeccion visual
for(i in 1:(dim(serie5)[2]-1))
{
s <- ts(serie5[, i], start = c(2008,1), frequency = 54)
class(s)
if(i %% 20==0) plot(s, main=as.character(names(serie5)[i]), xlab='series brutas')
}
par(mfrow=c(1,1))
# quitamos tendencia
quita.tendencia <- quita.tendencia.init(inicio= c(2008, 1),frecuencia = 12 )
series <- mclapply(FUN=quita.tendencia, serie5[,2:dim(serie5)[2]], mc.cores = 4)
install.packages("Cairo")
install.packages("imager")
install.packages("tiff")
N<-100
M<-200
beta<-1
tamanio_ensemble<-5000
L<-array(0,dim = c(length(MP_parametrizado(N,M,beta)),0))
#install.packages("QZ")
library(beepr)
library(RMTstat)
install.packages("beepr")
#install.packages("QZ")
library(beepr)
library(RMTstat)
library(QZ)
f.densidad <-function(N,M,beta)
{
# Entradas:
# N (numeric): numero de variables
# M (numeric): numero de observaciones
# beta(numeric): indica el ensamble LOE (1), LSE(4) y (2) LUO
if(beta == 1)
{
#Caso LOE
c <- N/M # la razon entre las dimensiones de la matriz
H <- matrix(rnorm(n = N*M,mean = 0,sd = 1),nrow = N,ncol = M ) #construimos la matriz densa
H <- H%*%t(H) # la hacemos simetrica
VP <- eigen(H)$values
}
if(beta == 2)
{
#CASO LUE
c <- N/M
Real <- rnorm(N*M,mean = 0,sd = 1)
Imaginaria <- rnorm(N*M,mean = 0,sd = 1)
H<- matrix(complex(real = Real,imaginary = Imaginaria),nrow = N,ncol = M )
H_t<- t(matrix(complex(real = Real,imaginary = -Imaginaria),nrow = N,ncol = M ))
W <- H%*%(H_t)
VP <- eigen(W)$values
}
if(beta == 4)
{
# caso LSE
library(QZ)
Real <- rnorm(N*M,mean = 0,sd = 1)
Imaginaria <- rnorm(N*M,mean = 0,sd = 1)
A <- matrix(complex(real = Real,imaginary = Imaginaria),nrow = N,ncol = M )
A_c <- matrix(complex(real = Real,imaginary = -Imaginaria),nrow = N,ncol = M )
Real <- rnorm(N*M,mean = 0,sd = 1)
Imaginaria <- rnorm(N*M,mean = 0,sd = 1)
B <- matrix(complex(real = Real,imaginary = Imaginaria),nrow = N,ncol = M )
B_c <- matrix(complex(real = Real,imaginary = -Imaginaria),nrow = N,ncol = M )
aux1 <- cbind(A,B)
aux2 <- cbind(-B_c,A_c)
H <- rbind(aux1,aux2)
W <- H%*%H(H)
VP <- eigen(W)$values
}
return(VP)
}
L<-array(0,dim = c(length(f.densidad(N,M,beta)),0))
nstall.packages("tictoc")
install.packages("tictoc")
for (i in 1:tamanio_ensemble) {
L<-cbind(L,MP_parametrizado(N,M,beta))
print(i)
}
L<-cbind(L,f.densidad(N,M,beta))
N<-100
M<-200
beta<-1
tamanio_ensemble<-5000
L<-array(0,dim = c(length(f.densidad(N,M,beta)),0))
for (i in 1:tamanio_ensemble) {
L<-cbind(L,f.densidad(N,M,beta))
print(i)
}
res<-hist(L,breaks = 100,col = "red",border = "black")
res<-density(L/100,n = 100)
valor<-density(rmp(n = tamanio_ensemble,ndf = 200,pdim = 100),n=100 )
ks.test(res$y, valor$y/2 )
valo
valor
valor$y
ks.test(res$y, valor$y/2 )
plot(res$x,res$y,main="Test K-S")
lines(valor$x*2,valor$y/2,col="blue")
ks.test(L, rmp(n = tamanio_ensemble,ndf = 200,pdim = 100))
ks.test(L/100, rmp(n = tamanio_ensemble,ndf = 200,pdim = 100)/2)
ks.test(L/100, rmp(n = tamanio_ensemble,ndf = 200,pdim = 100)/2, exact = TRUE)
?ks.test
ks.test(L/100, rmp(n = tamanio_ensemble,ndf = 200,pdim = 100)/2, exact = TRUE)
ks.test(L/100, rmp(n = tamanio_ensemble,ndf = 200,pdim = 100)/2, exact = FALSE)
13+15
devtools::install_github('diegovalle/mxmaps')
install.packages("sf")
load("/home/fou/Desktop/Ecobici/DataSubset/.RData")
1270*.2
load('serie_diaria.Rdata')
shiny::runApp('Desktop/Ecobici/Shiny')
runApp('Desktop/Ecobici/Shiny')
load('serie_diaria.Rdata')
setwd("/home/fou/Desktop/Ecobici/Data/")
load('serie_diaria.Rdata')
serie_diaria
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny/dwd')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
?boxcox
?box
?plotlyOutput
runApp('~/Desktop/Ecobici/Shiny')
?box
runApp('~/Desktop/Ecobici/Shiny')
?dashboardHeader
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
setwd("/home/fou/Desktop/Ecobici/DataSubset/")
library(readr)
library(lubridate)
library(hms)
load( file='tablaFiltro.Rdata')
library(ggplot2)
library(plotly)
names(tabla2)
tabla2%>% select(Genero_Usuario, Edad_Usuario ) %>% group_by(Genero_Usuario, Edad_Usuario) %>%
summarise(Porcentaje =n()) -> x
x %>% group_by(Genero_Usuario)%>% summarise(Porcentaje=sum(Porcentaje)) -> x
x$Porcentaje <- x$Porcentaje/sum(x$Porcentaje)
names(x) <- c('Genero', 'Porcentaje')
class(x) <- 'data.frame'
p <- ggplot(x, aes(x=Genero, y=Porcentaje, fill=Genero)) + geom_bar(stat = 'identity')  +
scale_fill_manual(values=c('#604B89', 'orange')) + theme_minimal() +xlab('') +ylab('') +
ggtitle('Distribución del generó')
p <- ggplotly(p)
tabla2 %>% group_by(Fecha_Retiro) %>% summarise(viajes=n()) -> viajes.salida
p
library(dplyr)
setwd("/home/fou/Desktop/Ecobici/DataSubset/")
library(readr)
library(lubridate)
library(dplyr)
library(hms)
load( file='tablaFiltro.Rdata')
library(ggplot2)
library(plotly)
names(tabla2)
tabla2%>% select(Genero_Usuario, Edad_Usuario ) %>% group_by(Genero_Usuario, Edad_Usuario) %>%
summarise(Porcentaje =n()) -> x
x %>% group_by(Genero_Usuario)%>% summarise(Porcentaje=sum(Porcentaje)) -> x
x$Porcentaje <- x$Porcentaje/sum(x$Porcentaje)
names(x) <- c('Genero', 'Porcentaje')
class(x) <- 'data.frame'
p <- ggplot(x, aes(x=Genero, y=Porcentaje, fill=Genero)) + geom_bar(stat = 'identity')  +
scale_fill_manual(values=c('#604B89', 'orange')) + theme_minimal() +xlab('') +ylab('') +
ggtitle('Distribución del generó')
p
p <- ggplotly(p)
tabla2 %>% group_by(Fecha_Retiro) %>% summarise(viajes=n()) -> viajes.salida
p
#############################################
names(viajes.salida)
sapply(viajes.salida, class)
p <- ggplot(viajes.salida, aes(x=dmy(Fecha_Retiro), y=viajes)) + geom_line(colour='#604B89') +
xlim(c(ymd('2017-01-01'), ymd('2018-10-31'))) + theme_minimal() + xlab('Fecha') + ylab('Viajes por día') +
ggtitle('Viajes en ECOBICI')
p
ggplotly(p)
save(p, file='DelimitacionTiempo.Rdata')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
load('DelimitacionTiempo.Rdata')
load('DelimitacionTiempo.Rdata')
setwd("~/Desktop/Ecobici/DataSubset")
load('DelimitacionTiempo.Rdata')
setwd("~/Desktop/Ecobici/Shiny")
load('DelimitacionTiempo.Rdata')
DelimitacionTiempo <- p
save(DelimitacionTiempo, 'DelimitacionTiempo.Rdata')
save(DelimitacionTiempo, file ='DelimitacionTiempo.Rdata')
load('DelimitacionTiempo.Rdata')
load('DelimitacionTiempo.Rdata')
runApp()
setwd("/home/fou/Desktop/Ecobici/DataSubset/")
library(readr)
library(lubridate)
library(dplyr)
library(hms)
load( file='tablaFiltro.Rdata')
library(ggplot2)
library(plotly)
names(tabla2)
tabla2%>% select(Genero_Usuario, Edad_Usuario ) %>% group_by(Genero_Usuario, Edad_Usuario) %>%
summarise(Porcentaje =n()) -> x
x %>% group_by(Genero_Usuario)%>% summarise(Porcentaje=sum(Porcentaje)) -> x
x$Porcentaje <- x$Porcentaje/sum(x$Porcentaje)
names(x) <- c('Genero', 'Porcentaje')
class(x) <- 'data.frame'
p <- ggplot(x, aes(x=Genero, y=Porcentaje, fill=Genero)) + geom_bar(stat = 'identity')  +
scale_fill_manual(values=c('#604B89', 'orange')) + theme_minimal() +xlab('') +ylab('') +
ggtitle('Distribución del generó')
p <- ggplotly(p)
tabla2 %>% group_by(Fecha_Retiro) %>% summarise(viajes=n()) -> viajes.salida
p
genero <- p
save(genero, file='genero.Rdata')
#############################################
names(viajes.salida)
sapply(viajes.salida, class)
p <- ggplot(viajes.salida, aes(x=dmy(Fecha_Retiro), y=viajes)) + geom_line(colour='#604B89') +
xlim(c(ymd('2017-01-01'), ymd('2018-10-31'))) + theme_minimal() + xlab('Fecha') + ylab('Viajes por día') +
ggtitle('Viajes en ECOBICI')
p
ggplotly(p)
hora <- p
###############################
# En que horarios hay mayor afluencia ?
##############################
tabla2 %>% select(Hora_Retiro) %>%  group_by(Hora_Retiro) %>% summarise(viajes=n()) -> horarios
horarios$Hora_Retiro <- as.hms(horarios$Hora_Retiro)
p <- ggplot(horarios, aes(x=Hora_Retiro , y=viajes)) + geom_line(colour='#604B89') +
theme_minimal() + xlab('Horario') + ylab('Viajes') +
ggtitle('Viajes en ECOBICI, por segundo')
p <- ggplotly(p)
p
hora <- p
save(hora, file='genero.Rdata')
load( file='tablaFiltro.Rdata')
library(ggplot2)
library(plotly)
names(tabla2)
tabla2%>% select(Genero_Usuario, Edad_Usuario ) %>% group_by(Genero_Usuario, Edad_Usuario) %>%
summarise(Porcentaje =n()) -> x
x %>% group_by(Genero_Usuario)%>% summarise(Porcentaje=sum(Porcentaje)) -> x
x$Porcentaje <- x$Porcentaje/sum(x$Porcentaje)
names(x) <- c('Genero', 'Porcentaje')
class(x) <- 'data.frame'
p <- ggplot(x, aes(x=Genero, y=Porcentaje, fill=Genero)) + geom_bar(stat = 'identity')  +
scale_fill_manual(values=c('#604B89', 'orange')) + theme_minimal() +xlab('') +ylab('') +
ggtitle('Distribución del generó')
p <- ggplotly(p)
tabla2 %>% group_by(Fecha_Retiro) %>% summarise(viajes=n()) -> viajes.salida
p
genero <- p
save(genero, file='genero.Rdata')
#############################################
names(viajes.salida)
sapply(viajes.salida, class)
p <- ggplot(viajes.salida, aes(x=dmy(Fecha_Retiro), y=viajes)) + geom_line(colour='#604B89') +
xlim(c(ymd('2017-01-01'), ymd('2018-10-31'))) + theme_minimal() + xlab('Fecha') + ylab('Viajes por día') +
ggtitle('Viajes en ECOBICI')
p
ggplotly(p)
hora <- p
###############################
# En que horarios hay mayor afluencia ?
##############################
tabla2 %>% select(Hora_Retiro) %>%  group_by(Hora_Retiro) %>% summarise(viajes=n()) -> horarios
horarios$Hora_Retiro <- as.hms(horarios$Hora_Retiro)
p <- ggplot(horarios, aes(x=Hora_Retiro , y=viajes)) + geom_line(colour='#604B89') +
theme_minimal() + xlab('Horario') + ylab('Viajes') +
ggtitle('Viajes en ECOBICI, por segundo')
p <- ggplotly(p)
p
hora <- p
save(hora, file='hora.Rdata')
runApp('~/Desktop/Ecobici/Shiny')
runApp('~/Desktop/Ecobici/Shiny')
load('genero.Rdata')
load('hora.Rdata')
setwd("~/Desktop/Ecobici/Shiny")
load('genero.Rdata')
load('hora.Rdata')
runApp()
shiny::runApp()
shiny::runApp('Desktop/MCE2/4/SPI2019/app')
runApp('Desktop/MCE2/4/SPI2019/app')
runApp('Desktop/MCE2/4/SPI2019/app')
runApp('Desktop/MCE2/4/SPI2019/app')
runApp('Desktop/MCE2/4/SPI2019/app')
runApp('Desktop/MCE2/4/SPI2019/app')
runApp('Desktop/MCE2/4/SPI2019/app')
runApp('Desktop/MCE2/4/SPI2019/app')
shiny::runApp('Desktop/MCE2/4/SPI2019/app')
runApp('Desktop/MCE2/4/SPI2019/app')
runApp('Desktop/MCE2/4/SPI2019/app')
runApp('Desktop/MCE2/4/SPI2019/app')
setwd("~/Desktop/MCE2/4/Consultoria/Cervezas")
# si te bajas los datos del drive esta parte no hace falta
#setwd("~/Desktop/MCE2/4/Consultoria/Cervezas")
library(lubridate) #esta sí
#catalogo <- read.csv('CATSKU_BI.txt', sep='|', stringsAsFactors = FALSE)
#catalogo$PRODUCTO_KEY <- as.character(catalogo$PRODUCTO_KEY)
#catalogo$UPC_CVE <- as.character(catalogo$UPC_CVE)
#sapply(catalogo, class)
#sku.cervezas <- unique(cervezas$id_producto)
#library(dplyr)
#catalogo %>% filter(PRODUCTO_KEY %in% sku.cervezas) -> catalogo.cervezas
#save(catalogo.cervezas, file = 'catalogoCervezas.rdata')
#save(cervezas, file = 'cervezas.rdata')
###########################################
load( file = 'catalogoCervezas.rdata') #catalogo con los detalles SOLO de las cervezas
load( file = 'cervezas.rdata') # todos los datos que nos paso Ramon
library(ggplot2)
names(cervezas)
sapply(cervezas, class)
summary(cervezas)
library(dplyr)
names(cervezas)
cervezas$loc <- NULL #esta columna no se ocupa
gc() #libera memoria
Sys.sleep(10) # el garbach collector de R no es determinista por eso siempre le doy 10 segundos para que sí libere espacio
nulos <- cervezas[is.na(cervezas$montomargen), ] #estos registros no tienen margen vamos a intentar imputarlos
imputacion <- cervezas[ cervezas$id_producto %in% unique(nulos$id_producto), ]
# pues para poder hacer una imputacion tendriamos que ver no solo el precio individual para tener el margen de utilidad sino
# tambien el tiempo -- YO DIGO QUE ESO PONGAMOS AL JONATHAN HA HACERLO---
remove(imputacion, nulos)
cervezas <- na.omit(cervezas)
gc()
Sys.sleep(10)
perdidas <- cervezas %>%filter(montomargen<0) # aqui ni ganancia hay
perdidas <- merge(perdidas, catalogo.cervezas,  all.x = TRUE, by.x='id_producto', by.y = 'PRODUCTO_KEY' )
# hechale un ojo al dataframe 'perdidas' no tienen descripcion y no parecen en el catalogo
#mira
perdidas1 <- cervezas %>%filter(montomargen<0) # aqui ni ganancia hay
perdidas2 <- merge(perdidas1, catalogo,  all.x = TRUE, by.x='id_producto', by.y = 'PRODUCTO_KEY' )
perdidas2 <- na.omit(perdidas2)
ggplot(perdidas2, aes(id_fecha, monto, color=PRODUCTO_DES))+geom_line()+theme_minimal()
sapply(perdidas2[, !(sapply(perdidas2, class) %in% c('character', 'Date')) ], sum) # pues no luce que sea una gran perdida
################
# le quitamos a las cervezas los nulos y los negativos
cervezas <- na.omit(cervezas)
cervezas <- cervezas%>% filter(montomargen>=0)
remove(catalogo, perdidas, perdidas1, perdidas2)
gc()
Sys.sleep(10)
# vamos ir reduciendo registros primero vamos a ver el acumulado diario de las cervezas
cervezas <- cervezas %>% group_by(id_producto, id_fecha) %>%summarise(cantidad=sum(cantidad, na.rm=TRUE),
monto=sum(monto, na.rm = TRUE),
montomargen=sum(montomargen, na.rm = TRUE))
gc()
Sys.sleep(10)
p1 <- ggplot(cervezas, aes(x=id_fecha, y=cantidad, color=factor(id_producto)))+
geom_line()+theme_minimal()
p1
# se nota que gace falta segmentar
ggplot(cervezas, aes(x=id_fecha, y=cantidad))+
geom_line()+theme_minimal() facet_grid(~id_producto)
# se nota que gace falta segmentar
ggplot(cervezas, aes(x=id_fecha, y=cantidad))+
geom_line()+theme_minimal()+ facet_grid(~id_producto)
# se nota que gace falta segmentar
ggplot(cervezas, aes(x=id_fecha, y=cantidad))+
geom_line()+theme_minimal()+ facet_grid(id_producto~)
?facet_grid
# se nota que gace falta segmentar
ggplot(cervezas, aes(x=id_fecha, y=cantidad))+
geom_line()+theme_minimal()+ facet_grid(id_producto~.)
# se nota que gace falta segmentar
ggplot(cervezas, aes(x=id_fecha, y=cantidad))+
geom_line()+theme_minimal()+ facet_grid(~id_producto)
