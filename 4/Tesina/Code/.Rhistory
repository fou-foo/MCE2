list.fore.var.pls[[ncomp]] <- fore.var.pls
list.mape.var.pls[[ncomp]] <- mape.var.pls
}
# combination models
c.num.cols <- ncol(data.into)
idx.matrix  <- as.data.frame(matrix(0, (lag.max - 1)*(seas.max - 1)*
length(ec.det), 3)) # aqui se ve porque salen 484 modelos
colnames(idx.matrix) <- c("seas", "lag", "ec.det") # esta matriz sirve como indicadora, contiene todas las combinaciones de
# lags, setacionalidades y formas (none, constante, trend y ambos)
idx.matrix[,"seas"] <- rep(2:seas.max, each = (length(ec.det))*(lag.max - 1))
idx.matrix[,"lag"] <- rep(c(2:lag.max), nrow(idx.matrix)/(lag.max - 1))
idx.matrix[,"ec.det"] <- rep(rep(ec.det, each = lag.max - 1), seas.max - 1)
# benchmark model ar(1)
ar1 <- sapply(1:ncol(data.into), function(x)
predict(arima(data.into[1:c(nrow(data.into)-h), x],
order = c(1,0,0)), n.ahead = h)$pred)
colnames(ar1) <- colnames(data.into)
# save data for test
test.data <- data.into[-c(1:c(nrow(data.into)-h)), ] # creo que esta linea se repite
test.data- data.fore
# matrix test
mat.test <- matrix(Inf, nrow(idx.matrix), 7)
colnames(mat.test) <- c("mape", "mdape", "rmspe", "rmdspe", "mrae",
"mdrae", "gmrae")
# runs all models
for(i in 1 : nrow(idx.matrix)){
# specification models
i.row <- idx.matrix[i, ]
i.lag <- i.row[,"lag"]
ec.det <- i.row[,"ec.det"]
seas <- i.row[,"seas"]
# season 2 is null
if(seas == 2)
seas <- NULL
# test forecast 1
var1.test <- VAR(data.into[1:c(nrow(data.into)-h), ], p = i.lag,
type = ec.det, season = seas)
fore.test <- predict(var1.test, n.ahead = h)
# matrix forecast
fore <- sapply(1:ncol(data.into), function(x) fore.test$fcst[[x]][,"fcst"]) # extrae los pronosticos de todas las variables en los h orizontes
mat.graph <- cbind(c(data.into[1:c(nrow(data.into)-h), 1], test.data[,1]),
c(rep(NA, nrow(data.into[1:c(nrow(data.into)-h), ])),
fore[,1])) # junta los datos test y los de pronostico
ts.plot(ts(mat.graph[-c(1:84),], start = as.numeric(c(unlist(strsplit(row.names(data.into[85,]), '/'))[c(3,2)])), frequency = 12),
col = c(1,2), lty = 1, lwd = 1)  #cuidado con este indice
abline(v = 2008 + 2/12, lty = 2, lwd = 1, col = "gray")
legend("topleft", c("p real", "forecast VAR"), col = c(1,2), lty = 1, lwd = 1)
title("VAR[i], out sample test for selected model")
# error with model 1
p.test <- sapply(1:ncol(data.into), function(x) c(test.data[,x]-fore[,x])/
test.data[,x]*100)
colnames(p.test) <- colnames(data.into)
# statsitics for error (model 1)
mape <- colMeans(abs(p.test))
mdape <- apply(p.test, 2, function(x) median(abs(x)))
rmspe <- sqrt(colMeans(p.test^2))
rmdspe <- sqrt(apply(p.test, 2, function(x) median(x^2)))
# relative errors for model 1
r.test <- sapply(1:ncol(data.into), function(x) c(test.data[,x] -
fore[,x])/c(test.data[,x] - ar1[,x]))
# statistics for relative error (model 1)
mrae <- colMeans(abs(r.test))
mdrae <- apply(r.test, 2, function(x) median(abs(x)))
gmrae <- apply(r.test, 2, function(x) geometric.mean(abs(x)))
# statistics models
mat.test[i,"mape"] <- mape[1]
mat.test[i,"mdape"] <- mdape[1]
mat.test[i,"rmspe"] <- rmspe[1]
mat.test[i,"rmdspe"] <- rmdspe[1]
mat.test[i,"mrae"] <- mrae[1]
mat.test[i,"mdrae"] <- mdrae[1]
mat.test[i,"gmrae"] <- gmrae[1]
}
# selected model
var.i <- apply(mat.test, 2, function(x) which(x == min(x)))
apply(mat.test, 2, function(x) min(x, na.rm = TRUE))
# save results
list.fore <- list.ci <- list()
# vars models selected
for(i in 1:length(var.i)){
# specification optimal
seas <- idx.matrix[var.i[i],"seas"]
if(seas == 2)
seas <- NULL
lags <- idx.matrix[var.i[i],"lag"]
type <- idx.matrix[var.i[i],"ec.det"]
# var model
var1 <- VAR(data.into, p = lags, type = type, season = seas)
fore.var <- predict(var1, n.ahead = h)
# fore
list.fore[[i]] <- sapply(1:ncol(data.into),
function(x) fore.var$fcst[[x]][,"fcst"])
# ci
list.ci[[i]] <- sapply(1:ncol(data.into),
function(x) fore.var$fcst[[x]][,"CI"])
colnames(list.fore[[i]]) <- colnames(list.ci[[i]]) <- colnames(data.into)
}
names(list.fore) <- names(list.ci) <- colnames(mat.test)
# output model
objective <- names(data)[1]
# integral forecast
fore.var <- sapply(1:length(var.i), function(x) list.fore[[x]][,objective])
colnames(fore.var) <- colnames(mat.test)
# integral ci
ci.var <- sapply(1:length(var.i), function(x) list.ci[[x]][,objective])
colnames(ci.var) <- colnames(mat.test)
# unique integral (mean & distribution quantile)
fore.int.var <- apply(fore.var, 1, function(x) quantile(x, probs = 0.5))
ci.int.var <- apply(ci.var, 1, function(x) quantile(x, probs = 0.5))
# mape with integral forecast
mape.int.var <- as.matrix(round(c(abs(c(data.fore[,objective] -
fore.int.var)/data.fore[,objective])), 4)*100)
colnames(mape.int.var) <- objective
# mape var models
mape.vars <- sapply(1:length(var.i),
function(x)
round(c(abs(c(data.fore[,objective] - fore.var[,x])/
data.fore[,objective])), 4)*100)
colnames(mape.vars) <- colnames(mat.test)
mape.var.pls <- sapply(1:c(K*p), function(x) list.mape.var.pls[[x]][,objective])
# models comparative
# all VAR-PLS vs integral VAR
comp1 <- sapply(1:c(K*p), function(x) mape.int.var > mape.var.pls[,x]) # errores de var mayores al pls
round(sum(comp1)/length(comp1), 4)*100 # es peor
# all VAR selected vs all VAR-PLS
comp2 <- list()
for(i in 1:length(var.i))
{
comp2[[i]] <- sapply(1:c(K*p),
function(x) mape.vars[,i] > mape.var.pls[,x]) #donde fue peor el var normal que el pls
}
names(comp2) <- colnames(mat.test)
round(sapply(1:length(var.i), function(x) sum(comp2[[x]])/
length(comp2[[x]])), 4)*100
# integral VAR-PLS
fore.var.pls <- sapply(1:c(K*p),
function(x) list.fore.var.pls[[x]]$Forecast[,objective])
# forecast
fore.int.var.pls <- apply(fore.var.pls, 1, function(x) quantile(x, probs = 0.5))
# mape with integral forecast
mape.int.var.pls <- round(abs(c(data.fore[,objective] - fore.int.var.pls)/
data.fore[,objective]), 4)*100
# integral VAR vs integral VAR-PLS
comp3 <- mape.int.var > mape.int.var.pls
sum(comp3)/h
# alls VAR cs integral VAR-PLS
comp4 <- mape.vars > mape.int.var.pls
round(sum(comp4)/length(comp4), 4)*100
mean(mape.int.var.pls)
# graph 1
inf <- function(x, q = 12)
{
inf.x <- c()
for(i in q:c(length(x) - 1))
inf.x[i - c(q-1)] <- c(x[i + 1]/x[i - c(q-1)])*100-100
return(inf.x)
}
data.g <- data
data.g[,4] <- data[,4] + 2 # por qu? le suma dos ??
# este grafico no tiene sentido
ts.plot(ts(data.g[,c(1,3,4)], start = as.numeric(c(unlist(strsplit(row.names(data[1,]), '/'))[c(3,2)])), frequency = 12), ylab = "log(x)",
col = c(1:3), lty = 1, lwd = c(2,1,1))
par(new=T)
matplot(data.g[,2], type = "l", xlab = "", ylab = "", yaxt = "n", xaxt = "n",
col = 4)
axis(4, col = 4, lwd = 2)
legend("top", c("p","y","r", "m0"), col = c(1:4), lwd = 1, lty = 1,
bg = "white", cex = 0.85)
title("Time Series of Mexican inflation model: 2000:01 - 2012:02")
min.var.pls <- which(colMeans(mape.var.pls) == min(colMeans(mape.var.pls)))
lower.var.pls <- sapply(1:c(K*p),
function(x) list.fore.var.pls[[x]]$Lower[,objective])
upper.var.pls <- sapply(1:c(K*p),
function(x) list.fore.var.pls[[x]]$Upper[,objective])
round(exp(fore.int.var) - exp(fore.int.var.pls), 2) #erores
round(exp(data.fore[,objective]) - exp(fore.int.var.pls), 2)
mat.fore.pls <- cbind(data[,objective],
c(data.into[,objective], fore.var.pls[,min.var.pls]),
c(data.into[,objective], lower.var.pls[,min.var.pls]),
c(data.into[,objective], upper.var.pls[,min.var.pls]))
mat.fore.pls[c(1:c(nrow(data.into)-1)),2] <- NA
mat.fore.pls[c(1:c(nrow(data.into))),3] <- NA
mat.fore.pls[c(1:c(nrow(data.into))),4] <- NA
mat.fore.pls <- mat.fore.pls[-c(1:c(12*8)),]
mat.fore.pls <- ts(mat.fore.pls, start = as.numeric(c(unlist(strsplit(row.names(data[97,]), '/'))[c(3,2)])), frequency = 12)
ts.plot(mat.fore.pls, col = c(1,2,4,4), lwd = 2, lty = 1)
abline(v = 2009 + 2/12, col = "gray", lty = 2, lwd = 1)
legend("topleft", c("p-real", "p-forecast", "lower(0.05) & upper(0.95)"),
col = c(1,2,4), lwd = 2, lty = 1, cex = 0.85, bg = "white")
title(paste("Forecast series ",objective,
": VAR(",p,")-PLS(h=",h,",k=",min.var.pls,")", sep = ""))
mat.fore.var <- cbind(data[,objective],
c(data.into[,objective], fore.int.var),
c(data.into[,objective], fore.int.var - ci.int.var),
c(data.into[,objective], fore.int.var + ci.int.var))
mat.fore.var[c(1:c(nrow(data.into)-1)),2] <- NA
mat.fore.var[c(1:c(nrow(data.into))),3] <- NA
mat.fore.var[c(1:c(nrow(data.into))),4] <- NA
mat.fore.var <- mat.fore.var[-c(1:c(12*8)),]
mat.fore.var <- ts(mat.fore.var, start = as.numeric(c(unlist(strsplit(row.names(data[97,]), '/'))[c(3,2)])), frequency = 12)
ts.plot(mat.fore.var, col = c(1,2,4,4), lwd = 2, lty = 1)
abline(v = 2009 + 2/12, col = "gray", lty = 2, lwd = 1)
legend("topleft", c("p-real", "p-forecast", "lower(0.05) & upper(0.95)"),
col = c(1,2,4), lwd = 2, lty = 1, cex = 0.85, bg = "white")
title(paste("Forecast series ",objective,": Integral-VAR", sep = ""))
matrix.mape <- matrix("black", nrow = nrow(comp1),
ncol = ncol(comp1))
matrix.mape[comp1] <- "blue"
plot(1, type = "p", ylim = c(1,h+2), xlim = c(1,c(p*K)), ylab = "h",
xlab = "k")
for(j in 1 : c(p*K))
{
for(i in 1 : h)
{
points(x=j, y = i, type = "p", pch = 18, col = matrix.mape[i,j])
}
}
legend("top", c("Integral VAR", "VAR-PLS"), col = c("black", "blue"),
pch = 18, cex = 0.75, bg = "white")
title("Integral VAR vs VAR-PLS (Comparasion with MAPE)")
summary(var.pls1$pls.model)
colMeans(list.mape.var.pls[[min.var.pls]])
mean(mape.int.var)
cumsum(round(var.pls1$pls.model$Xvar/var.pls1$pls.model$Xtotvar, 6))
####
# Errores relativos
errores.pls <- abs((exp(tail(mat.fore.pls[, 2],h))-exp(tail(data$InflacionNacional,h)))/exp(tail(data$InflacionNacional,h)))
(errores.porcentuales <- errores.pls*100)
(error.medio.pls <- mean(errores.porcentuales))
#
errores.var <- abs( (exp(tail(mat.fore.var[,2], h))- exp(tail(data$InflacionNacional,h)))/  exp(tail(data$InflacionNacional,h)) )
(errores.porcentuales.var <- errores.var*100)
(error.medio.var <- mean(errores.porcentuales.var ))
##verificacion
(errores.porcentuales <- errores.pls*100) < (errores.porcentuales.var <- errores.var*100)
mat.fore.pls <- cbind(data[,objective],
c(data.into[,objective], fore.var.pls[,min.var.pls]),
c(data.into[,objective], lower.var.pls[,min.var.pls]),
c(data.into[,objective], upper.var.pls[,min.var.pls]))
mat.fore.pls[c(1:c(nrow(data.into)-1)),2] <- NA
mat.fore.pls[c(1:c(nrow(data.into))),3] <- NA
mat.fore.pls[c(1:c(nrow(data.into))),4] <- NA
mat.fore.pls <- mat.fore.pls[-c(1:c(12*8)),]
mat.fore.pls <- ts(mat.fore.pls, start = as.numeric(c(unlist(strsplit(row.names(data[97,]), '/'))[c(3,2)])), frequency = 12)
ts.plot(mat.fore.pls, col = c(1,2,4,4), lwd = 2, lty = 1)
abline(v = 2009 + 2/12, col = "gray", lty = 2, lwd = 1)
legend("topleft", c("p-real", "p-forecast", "lower(0.05) & upper(0.95)"),
col = c(1,2,4), lwd = 2, lty = 1, cex = 0.85, bg = "white")
title(paste("Forecast series ",objective,
": VAR(",p,")-PLS(h=",h,",k=",min.var.pls,")", sep = ""))
ts.plot(diff(mat.fore.pls), col = c(1,2,4,4), lwd = 2, lty = 1)
ts.plot(diff(exp(mat.fore.pls)), col = c(1,2,4,4), lwd = 2, lty = 1)
runApp('~/Desktop/ExperimentosShiny')
l <- 5
n <- 166
set.seed(0)
y <- matrix(nrow = n, ncol=l)
y[1, ] <- runif(l, -2, 2)
y[2, ] <- runif(l, -2, 2)
a1 <- runif(l*l, -.5, .5)
dim(a1) <- c(l,l)
a2 <- runif(l*l, -.5, .5 )
dim(a2) <- c(l,  l)
# ar
for(i in 3:n)
{
y[i, ] <- a1%*%y[i-1,] + a2%*%y[i-2, ] + rnorm(l)
}
library(vars)
plot(ts((y)))
p <- VARselect(y)
p <- p$selection[4]
colnames(y) <- paste0('V', 1:(l))
a <-ca.jo(y)
summary(a)
simulacion <- as.data.frame(y)
# Closure para poder paralelizar la funcion 'CarloMagno'
Rellena <- function(dataframe, dataframe.pares, index, crit, lag.max)
{
# Entradas:
# dataframe (data.frame): Conjunto de datos original
# dataframe.pares (data.frame): Tabla con todas las posibles combinaciones por pares de variables
# index (int): variable anonima
# crit (character): Sttring con el criterio para determinar el orden del VAR(p)
# lag.max (int): Parametro para determinacion del orden del VAR(p)
# Salidas: Funcion que determina si dos variables son cointegradas
data <- dataframe
Cointegracion.pares <- dataframe.pares
crit <- crit
lag.max <- lag.max
function(index)
{
series <- Cointegracion.pares[index, names(Cointegracion.pares)[1:2] ]
series <- unlist(series)
datos <- data[, series ]
p.mini <- VARselect(y= datos, lag.max = lag.max, type = "const")$selection[crit]
l <- ca.jo(datos, K= p.mini)
rango1 <- l@cval[ 1  , significancia] # valor critico para rango <=1 El numero magico es porque siempre hay solo dos series
estadistico1 <- l@teststat[1]
resultado <- ifelse( estadistico1 < rango1, 'Si', 'No')
return(resultado)
}
# Funcion para determinar si existe cointegracion en un VAR con mas de once variables, basado en el paper de
# Discovering common trends in a large set of disaggregates: statistical procedures and their properties
# En el mismo paper se da otra propuesta para el caso de cientos
# requiere de las librerias 'vars' y parallel
CarloMagno <- function(data, significancia='1pct', crit = 'FPE(n)')
{
# Entradas:
# data (data.frame): Conjunto de datos original
# significancia (string): Significancia de la prueba '1pct', '5pct', '10pct'
# crit (string): criterio para seleccion del orden del VAR(p) FIJO DE MOMENTO
# Salidas:
# cointegracion.grande (character): Mensaje indicando si hay o no cointegracion
K <- dim(data)[2]
# La primer etapa consite en encontrar cointegracion por pares
Cointegracion.pares <- as.data.frame( t(combn(K, 2))) #las combinaciones por pares de variables
Cointegracion.pares$Cointegran <- ''
Rellena.cointegracion <- Rellena(dataframe=data, dataframe.pares=Cointegracion.pares,  crit=crit, lag.max=lag.max)
Cointegracion.pares$Cointegran <- mapply(function(x){Rellena.cointegracion(x)}, 1:dim(Cointegracion.pares)[1])
if( !('No' %in% Cointegracion.pares$Cointegran ) )
{
cointegracion.grande <- 'Todas las variables cointegran'
return(cointegracion.grande)
} else{
cointegracion.grande <- 'No todas las variables cointegran'
}
CarloMagno(simulacion)
# Closure para poder paralelizar la funcion 'CarloMagno'
Rellena <- function(dataframe, dataframe.pares, index, crit, lag.max)
{
# Entradas:
# dataframe (data.frame): Conjunto de datos original
# dataframe.pares (data.frame): Tabla con todas las posibles combinaciones por pares de variables
# index (int): variable anonima
# crit (character): Sttring con el criterio para determinar el orden del VAR(p)
# lag.max (int): Parametro para determinacion del orden del VAR(p)
# Salidas: Funcion que determina si dos variables son cointegradas
data <- dataframe
Cointegracion.pares <- dataframe.pares
crit <- crit
lag.max <- lag.max
function(index)
{
series <- Cointegracion.pares[index, names(Cointegracion.pares)[1:2] ]
series <- unlist(series)
datos <- data[, series ]
p.mini <- VARselect(y= datos, lag.max = lag.max, type = "const")$selection[crit]
l <- ca.jo(datos, K= p.mini)
rango1 <- l@cval[ 1  , significancia] # valor critico para rango <=1 El numero magico es porque siempre hay solo dos series
estadistico1 <- l@teststat[1]
resultado <- ifelse( estadistico1 < rango1, 'Si', 'No')
return(resultado)
}
# Funcion para determinar si existe cointegracion en un VAR con mas de once variables, basado en el paper de
# Discovering common trends in a large set of disaggregates: statistical procedures and their properties
# En el mismo paper se da otra propuesta para el caso de cientos
# requiere de las librerias 'vars' y parallel
CarloMagno <- function(data, significancia='1pct', crit = 'FPE(n)', lag.max)
{
# Entradas:
# data (data.frame): Conjunto de datos original
# significancia (string): Significancia de la prueba '1pct', '5pct', '10pct'
# crit (string): criterio para seleccion del orden del VAR(p) FIJO DE MOMENTO
# lag.max (int): Limite para los lags de todos los VAR(p) se se estiman
# Salidas:
# cointegracion.grande (character): Mensaje indicando si hay o no cointegracion
K <- dim(data)[2]
# La primer etapa consite en encontrar cointegracion por pares
Cointegracion.pares <- as.data.frame( t(combn(K, 2))) #las combinaciones por pares de variables
Cointegracion.pares$Cointegran <- ''
Rellena.cointegracion <- Rellena(dataframe=data, dataframe.pares=Cointegracion.pares,  crit=crit, lag.max=lag.max)
Cointegracion.pares$Cointegran <- mapply(function(x){Rellena.cointegracion(x)}, 1:dim(Cointegracion.pares)[1])
if( !('No' %in% Cointegracion.pares$Cointegran ) )
{
cointegracion.grande <- 'Todas las variables cointegran'
return(cointegracion.grande)
} else{
cointegracion.grande <- 'No todas las variables cointegran'
}
CarloMagno(simulacion, lag.max = 10)
remove(list=ls()) # removemos todos los objetos del enviroment
{
###########################################
# librerias                               #
{
library(vars) # tiene varias dependencias (implicitamente carga en el ambiente otras) util para modelos VAR
library(pls)  # para estimacion pls
library(psych) # solo ocupamos una funcion de aqui CHECAR CUAL ES
library(ggplot2) # libreria de graficos
library(lubridate)  # libreria para manejo de fechas
library(reshape2) #manipulacion de dataframes
library(parallel)
}
###########################################
# Parametros                              #
{
path <- 'C:\\Users\\fou-f\\Documents\\GitHub\\MCE2\\4\\Tesina\\Code\\' # ubicacion del archivo 'Funciones_VARPLSParallel.R' y los datos
h <- 6 # numero de steps a pronostricar
lag.max <- 6 # lag maximo para la determinacion inicial del AR(p)
runs <- 1000  # numero de iteraciones bootstrap para los intervalos de confianza
crit <- "FPE(n)" # criterio con cual elegir el orden inicial del VAR(p)
confianza <- .95
}
source(paste0(path, "Funciones_VARPLSParallel.R"))# cargar funciones auxiliares
##########################################
# Lectura de datos                       #
# Se espera un dataframe donde la primer columna sean las fechas de las series y la segunda la variable de interes a pronosticar
data <- read.csv(paste0(path, "Compendio16junio2019.csv"), row.names = 1)
##########################################
# imputacion de datos                    #
data <- na.omit(data)
temp <- row.names(data)
data <- as.data.frame(sapply(data, log))
row.names(data) <- temp
data2 <- data
#data[, 3:17] <- NULL
##########################################
# visualizacion
data.s <- data
data.s$time <- row.names(data)
data.s$time <- dmy(data.s$time)
data.s <- melt(data.s, id='time')
ggplot(data.s, aes(x= time, y =exp(value), color=variable)) + geom_line() +
facet_wrap(variable~., scales = "free") +  theme_minimal() + xlab('') +
ylab('') +  theme(legend.position = "bottom", legend.title = element_text(color = "white")) +
ggtitle('Variables econometrícas') +guides( color=FALSE)
###########################################
fechas <- row.names(data) # guardamos las fechas
row.names(data) <- fechas
# division de la muestra como sugiere Frances
n <- dim(data)[1] # tamaÃ±o total de la muestra
k <- dim(data)[2] # numero de componentes
Y <- tail(data, n - h + 1 )
X <- head(data, n - h + 1 )
# test de cointegracion de
CarloMagno(data, lag.max=lag.max)
p <- VARselect(y= X, lag.max = lag.max)$selection[crit]# determinacion del orden del VAR(p)
Y <- Y[ dim(Y)[1]:1, ] # Frances propone este acomodo de las observaciones
X <- X[ dim(X)[1]:1, ]
Y <- as.data.frame(Y)
X <- as.data.frame(X)
colnames(Y) <- colnames(X) <- colnames(data)
X.lags <- SpanMatrix(X, p=(p))# generamos la matriz extendida con todos los lags
Y.lags <- SpanMatrix(X, p=(h-1))# generamos la matriz extendida con todos los lags
model <- plsr(Y.lags~ X.lags, method = "simpls", x=TRUE, y=TRUE)
componentes.practicas <- model$ncomp # por los nulos se reducen
Pronosticos <- mclapply(FUN=function(x) Predict.PLS(modelo=model, original=Y, ncomp=x, h=h),
1:componentes.practicas)
temp1 <- temp <- matrix(nrow = componentes.practicas, ncol = dim(data)[2])
temp1 <- temp <- as.data.frame(temp)
colnames(temp1) <- colnames(temp) <- colnames(data)
row.names(temp1) <- row.names(temp) <- paste0('Comp.', 1:componentes.practicas)
for(i in 1:componentes.practicas)
{
temp[i, ] <- Error.relativo(Pronosticos[[i]], ncomp = i, data, h)
temp1[i, ] <- MAPE(x=Pronosticos[[i]], ncomp=i, data, h)
}
temp1$id <- 1:componentes.practicas
Ncomp <- which.min(temp[, 1])
}
# grafica de mape
z <- melt(temp1, id='id')
Ncomp.mape <- which.min(temp1[, 1])
ggplot(z, aes(x=id, y=value, color=variable)) + geom_line() +
facet_wrap(variable~., scales = "free") +  theme_minimal() + xlab('') +
ylab('') +  theme(legend.position = "bottom", legend.title = element_text(color = "white")) +
ggtitle('MAPE') +guides( color=FALSE)
###################
# intervalos de confianza
set.seed(0)
Intervalos <- mclapply(rep(p, runs), function(x) Bootstrap(x=X, X.lags = X.lags, p=x, Y=Y, Y.lags = Y.lags, Ncomp.mape=Ncomp.mape)  )
intervalos <- do.call('rbind', Intervalos)
intervalos <- as.data.frame(intervalos)
significancia <- (1 - confianza)/2
c.i <- lapply(intervalos, function(x)quantile(x, probs=c(significancia, 1-significancia )) )
c.i <- as.data.frame(do.call('rbind', c.i))
c.i$l <- c.i[, 2] -c.i[, 1]
#######################################################
### estimacion del VAR a comparar
var <- VAR(ts(data2, start = c(2015, 1), frequency = 12), p=p, ic='FPE',
lag.max = lag.max )
tabla.var <- data.frame(Pronostico=predict(var, n.ahead = h)$fcst$InflacionNacional[,'fcst'],
y = tail(data2[,1],h ))
tabla.var$Error.relativo <- abs(tabla.var$y - tabla.var$Pronostico)/abs(tabla.var$Pronostico)*100
tabla.var
tabla.var$Error.relativo <- abs(tabla.var$y - tabla.var$Pronostico)/abs(tabla.var$y)*100
tabla.var
mean(tabla.var$Error.relativo)
######################################
# plot de pronostico conjunto
Final <- data.frame(Valor.Real=tail(data2[,1], h) ,
VAR.PLS = Predict.PLS(modelo=model, original=Y, h = h, ncomp=Ncomp.mape)[,1],
VAR=predict(var, n.ahead = h)$fcst$InflacionNacional[,'fcst'])
tabla <- Final <- exp(Final)
Final <- cbind(Final, c.i[, 1:2])
Final[, 4] <- Final$VAR.PLS - Final[, 4]
Final[, 5] <- Final$VAR.PLS + Final[, 5]
Final$t <- dmy(row.names(tail(data, h)))
data <- exp(data2)
data$t <- dmy(row.names(data))
t <- melt(Final, id='t')
tabla$Error.relativo.pls <- abs(tabla$Valor.Real - tabla$VAR.PLS )/abs(tabla$Valor.Real)*100
tabla$Error.relativo.var <- abs(tabla$Valor.Real - tabla$VAR )/abs(tabla$Valor.Real)*100
tabla
tabla$Presicio.VAR.PLS <- 100 - tabla$Error.relativo.pls
tabla$Presicio.VAR <- 100 - tabla$Error.relativo.var
library(xtable)
xtable(tabla)
sapply(tabla, mean)
xtable(Final[, c(2, 4,5)])
xtable(tabla)
