---
title: 'Sobre la elección del número de componentes principales,'
subtitle: 'desde el criterio del codo hasta los resultados de matrices aleatorias'
author: J. Antonio García R.
date: 5 de febrero, 2019
output:
  beamer_presentation:
    theme: "CambridgeUS"
    colortheme: "beaver"
    fonttheme: "structurebold"
header-includes:
    - \usepackage[spanish]{babel}
    - \usepackage{graphicx}
---
---

# Esquema

 * Motivación
 * Objetivo
 * Experimento
 
    - Instancias 
    - EDA
    - Implementación y  __determinación del número de componentes__ 
    
 * Resultados
 * Conclusiones
 * Trabajos Futuros
 * Anexo: Extensiones
 * Bibliografía
  
  
  
# Motivación

\begin{itemize}

    \item Análisis multivariado: número de factores a mantener (PCA, FA, ...) 

    \item Contexto \textbf{variables latentes}

    \item Reducción de dimensión (peculiaridades, cuando $N<<p$)
    
    \item Series de tiempo (DFM, multicolinealidad)

\end{itemize}


#  Objetivo

\begin{center}
 
 Confrontar la elección del número de factores a considerar, para la tarea de predicción que requieren algunos métodos de reducción de dimensión
 
\end{center}

Evaluamos el desempeño de regresión por componentes principales (PCR) y la regresión por mínimos cuadrados parciales (PLS).

Muchas técnicas \footnote{MDS o la regresión por componentes supervisada,... }  requieren de precisar el número de componentes a utilizar, lo cual involucra un criterio de selección. 

# Experimento

Comparamos 3 métodos: El criterio de Kaiser \cite{kaiser} (criticado en sus aspectos teóricos y muestrales en \cite{horn}), el Parallel Analysis y proponemos uno basado en el teorema de Marchenko-Pastur

El __Parallel Analysis__ conlleva simular matrices de correlación de una función de distribución multivariada desconocida por lo que es imperativo una implementación eficiente.

 


# El experimento

Se construyeron tres instancias, con las mismas dimensiones ($515,345 \times 90$) y con la misma partición para entrenamiento y prueba ($463,715$ y $51,630$)

\[Y = \sum_{i=0}^{90}x_i\beta_i + e_i \]

* La primera consiste en 90 variables con distribución $N(0,\sigma_i)$.

* La segunda con 90 variables con distribución $Rayleigh(\sigma_i)$. 

* La tercera es uno de los datasets de \textit{Million Song Dataset}, con información de canciones \footnote{Tiene entre uno de sus fines alentar la investigación en algoritmos a escalas comerciales (por lo cual lo encontramos de interés)}. Lanzadas en [1978,2011]

# EDA


![No. de canciones por año en el conjunto de datos de la instancia 3](img/freq_canciones.png)

# PCA


![Proyección de dos muestras (0.1\% y 1\% del total ), varianza explicada 19\%.](img/pca.png)



# Linealidad ?

![Correlación entre $Y$ y las variables exógenas.](img/correlograma.png)

# Implementación

  * Kaiser: Eigendescomposición
  * Parallel analysis:
  
    - Muestreo apriori
    - Bootstrap
  
  * M-K: Simulación y promedio $O(n)$

La implementación es conceptualmente fácil de paralelizar, en una arquitectura multihilo. Los cálculos fueron efectuados en una instancia Standard F16s\_v2 (16 vcpu, 64 GB de memoria) de un proveedor de servicios en la nube 




# Instancia 1 (1000 monte-carlo)

![Boostrap instancia 1](img/parallel_unif.png)



# Instancia 1 

![Densidades muestrales](img/parallel_unif_densidade.png)


# Instancia 2 (1000 monte-carlo)

![](img/ray_densidades.png)


# Instancia 2 (1000 monte-carlo)

![](img/ray_densidades_RMT.png)


# Resumen instancias 1 y 2

Los resultados en estas instancias son los esperados: el criterios de Kaiser, el parallel analysis uniforme y con bootstrap sugieren el mismo número de componentes (45, el punto en donde las curvas se intersectan).\footnote{ El criterio 'del codo' ?}

La distribución límite de Marchenko Pastur encierra a todos los valores propios, esto nos sugiere que el criterio que estamos tomando usando  resultados de matrices aleatorias podrían extenderse, a las distribuciones de la familia exponencial

# Caso práctico


![Bootstrap caso práctico](img/paralllel_prac_big.png)



# Comentario simulación intancia 3

El parallel analysis presenta menor varianza que en las dos instancias anteriores, i.e. las muestras simuladas son igual de 'informativas' que la original


# Instancia 3 (Million Song Dataset)


![](img/practica_emp1.png)

# Instancia 3 (Million Song Dataset, zoom)

![](img/practica_emp2.png)

# Resultados

Resumimos los números de componentes que propone cada criterio sobre las tres instancias, así como sus respectivos tiempos de cómputo que requiere la simulación:

\begin{center}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
Id  & Kaiser &  Uniforme & Bootstrap & M-P & Tiempo\\
\hline
1 & 45 & 45 &  45 & 46 &  12.2mins + 36.54 mins \\
2 & 45  &45& 45&  45 & 13.54 mins + 44.25 mins\\
3 & 25 & 31  & 37 & 27 & 13.02 mins + 50.41 mins  \\
\hline
\end{tabular}
\end{center}



# Resultados (regresión)


En un trabajo del donador de los datos \cite{paper} se reporta un error sobre el conjunto de prueba de 10.20 y 8.76 (medido en la misma escala que en nuestro experimento) utilizando el método de 50 vecinos más cercanos y el algoritmo de Vowpal Wabbit. Nuestro resultado final es de \textbf{9.5}. casi en el punto medio sin embargo nosotros nos restringimos a métodos de regresión lineales.


# Conclusiones

Nuestro criterio basado en la distribución de Marchenko Pastur:
 
  - Ahorra de recursos para la elección del número de componentes frente a cv en PCR.
  
  - Acota el espacio de búsqueda de las componentes de PLS.

 
 Diseñamos un experimento de simulación donde se tienen tres estratos el primero muy cercano a los supuestos necesarios del teorema de Marchenko-Pastur\footnote{Cuyo paper original se encuentra en ruso \includegraphics[height=5.0mm]{img/carita_miedo.PNG}}, el segundo no satisfaciendo la normalidad y el tercero (datos reales) solo con media cero y desviación estándar estimada igual a la unidad.
 


- La estimación utilizando técnicas de reducción de dimensionalidad, en particular PLS con una proporción bastante pequeña respecto al número de variables siempre presentó un mejor desempeño aún en casos teóricos y prácticos.


# Conclusión

- La agregación puede aportar grandes ganancias por encima de los componentes individuales, NO FUERZA BRUTA

- Citando a Stephen M. Stigler \footnote{ver \cite{ame} pág. 23} sobre el cuento de Jorge Luis Borges \textit{Funes el memorioso} de 1942

\begin{center}
\textit{  \large\textbf{{Funes era big data sin estadística}}}
\end{center}


# Trabajos Futuros

Extender el criterio definido en este trabajo 

- Implementación en paralelo del 'test' (en una arquitectura GPU) \footnote{Horn a finales de su trabajo \cite{horn} sugiere implementar un método en el software estadístico (pues al día de hoy desconocemos una implementación popular)}

- Utilizar el test en conjuntos de datos con alta correlación donde esperamos mejores resultados aunque esto requiere de una adaptación de PLS.

- Probar su utilidad y robustez en modelos de cointegración y factores dinamicos en series de tiempo.  

# Anexo

Hemos encontrado que nuestro criterio se desempeña mejor en la regresión PCR y PLS al pronosticar el indice SP500 que no requiere de estacionalidad y estacionariedad en los datos. Sin embargo el número de componentes del criterio es __dependiente__ de realizar las transformaciones sobre las series de tiempo mencionadas. 


En \cite{copia} se desarrolla un nuevo criterio de selección de componentes 'Empirical Kaiser Criterion' cuya metodología es ligeramente diferente a la desarrollada. 
 

#

\begin{thebibliography}{1}

\bibitem{copia}
Braeken, J., y van Assen, M. A. L. M. \textit{An empirical Kaiser criterion}. Psychological Methods, 22(3), 450-466. http://dx.doi.org/10.1037/met0000074, 2017.

\bibitem{actanumericachafa}
A. Edelman; \textit{Random Matrix Theory and its Innovative Applications};2013.

\bibitem{horn}
Horn, J. L.; \textit{A Rationale and Test For the Number of Factors in Factor Analysis}; Psychometrika, 30, 179-85; 1965.


\bibitem{kaiser}
Kaisert H.; \textit{The application of electronic computers to factor analysis}; Paper read at
a symposium on application of computers to psychological problems. Meeting of Amer. Psychol. Ass., 1959. 

\end{thebibliography}

#

\begin{thebibliography}{1}





\bibitem{ame}
Stephen M. Stigler; \textit{Los siete pilares de la sabiduría estadística}; Libros Grano de Sal, 1er edición 2017.


\bibitem{paper}
T. Bertin-Mahieux, D. P.W. Ellis,B. Whitman y P. Lamere ; \textit{THE MILLION SONG DATASET}; recuperado de \url{https://www.ee.columbia.edu/~dpwe/pubs/BertEWL11-msd.pdf} el 3 de noviembre de 2018.\\



\end{thebibliography}